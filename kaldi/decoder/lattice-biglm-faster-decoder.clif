from "itf/decodable-itf-clifwrap.h" import *
from "itf/options-itf-clifwrap.h" import *
from "fstext/lattice-weight-clifwrap.h" import *
from "fstext/fst-clifwrap.h" import *
from "fstext/mutable-fst-clifwrap.h" import *
from "fstext/deterministic-fst-clifwrap.h" import *
from "lat/determinize-lattice-pruned-clifwrap.h" import *
from "decoder/lattice-faster-decoder-clifwrap.h" import *

from "decoder/lattice-biglm-faster-decoder.h":
  namespace `kaldi`:

    class LatticeBiglmFasterDecoder:
      """LatticeBiglmFasterDecoder(fst, config, lm_diff_fst)

      Lattice generating faster decoder for decoding with big language models.

      This is as LatticeFasterDecoder, but does online composition between HCLG
      and the difference language model, which is a deterministic FST that
      represents the difference between the language model you want and the
      language model you compiled HCLG with. The class DeterministicOnDemandFst
      follows through the epsilons in G for you (assuming G is a standard
      backoff language model) and makes it look like a determinized FST.

      Args:
        fst (StdFst): Decoding graph.
        config (LatticeFasterDecoderOptions): Decoding options.
        lm_diff_fst (StdDeterministicOnDemandFst): The FST representing the
          difference in LM scores between the LM we want to decode with and
          the LM the decoding graph :attr:`fst` was built with.
      """
      def __init__(self, fst: StdFst, config: LatticeFasterDecoderOptions,
                   lm_diff_fst: StdDeterministicOnDemandFst)

      def `SetOptions` as set_options(self,
                                      config: LatticeFasterDecoderOptions):
        """Sets decoder options."""

      def `Decode` as decode(self, decodable: DecodableInterface) -> bool:
        """Decodes all frames in the decodable object.

        This may block waiting for input if the "decodable" object blocks.

        Returns:
          True if any kind of traceback is available (not necessarily from a
          final state).
        """

      def `ReachedFinal` as reached_final(self) -> bool:
        """Check if decoding reached a final state of the graph.

        Returns:
          True if a final state of the graph was active on the last frame.
        """

      def `GetBestPath` as get_best_path(self,
          fst_out: LatticeMutableFst, use_final_probs: bool = default) -> bool:
        """Gets best path as an FST.

        If 'use_final_probs' is true and we reached a final state of the graph,
        then the output will include final probabilities given by the graph;
        otherwise all final probabilities are treated as one.

        Returns:
          True if the output best path is not empty,
          False in the unusual circumstances where no tokens survive.
        """

      def `GetRawLattice` as get_raw_lattice(self,
          fst_out: LatticeMutableFst, use_final_probs: bool = default) -> bool:
        """Gets raw state-level lattice.

        If 'use_final_probs' is true and we reached a final state of the graph,
        then the output will include final probabilities given by the graph;
        otherwise all final probabilities are treated as one.

        The output raw lattice will be topologically sorted.

        Returns:
          True if the output is not empty.
        """

      def `GetLattice` as get_lattice(self, fst_out: CompactLatticeMutableFst,
                                      use_final_probs: bool = default) -> bool:
        """Gets the lattice-determinized lattice.

        The output is a deterministic compact lattice with a unique path for
        each word sequence.

        If 'use_final_probs' is true and we reached a final state of the graph,
        then the output will include final probabilities given by the graph;
        otherwise all final probabilities are treated as one.

        Returns:
          True if the output is not empty.
        """
